{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f91f20",
   "metadata": {},
   "source": [
    "# Writer Tools\n",
    "\n",
    "\n",
    "This notebook provides a quick overview for getting started with Writer [tools](https://python.langchain.com/docs/concepts/tools/). For detailed documentation of all Writer features and configurations head to the [Writer docs](https://dev.writer.com/home).\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Integration details\n",
    "\n",
    "| Class                                                                                                      | Package          | Local | Serializable | JS support |                                        Package downloads                                         |                                        Package latest                                         |\n",
    "|:-----------------------------------------------------------------------------------------------------------|:-----------------| :---: | :---: |:----------:|:------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n",
    "| [GraphTool](https://github.com/writer/langchain-writer/blob/main/langchain_writer/tools.py#L9) | [langchain-writer](https://pypi.org/project/langchain-writer/) |      ❌       |                                       ❌                                       | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-writer?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-writer?style=flat-square&label=%20) |\n",
    "\n",
    "### Features\n",
    "\n",
    "We provide usage of four types of tools for use with `ChatWriter`: `function`, `llm`, `graph` and `application`.\n",
    "\n",
    "#### Function\n",
    "\n",
    "Functions are the most common type of tool, which allows the LLM to call external APIs, fetch data from databases, and generally perform any external action you want to do. Visit our [tool calling docs](https://dev.writer.com/api-guides/tool-calling#tool-calling) for additional information.\n",
    "\n",
    "#### Graph\n",
    "\n",
    "The `Graph` tool is Writer's graph-based retrieval-augmented generation (RAG) called Knowledge Graph. This tool enables developers to simply pass the graph ID to the model, and it will return the answer to the question in the prompt. To learn more, see our [Knowledge Graph API docs](https://dev.writer.com/api-guides/knowledge-graph).\n",
    "\n",
    "#### LLM\n",
    "\n",
    "The `LLM` tool is a Writer specific tool, which allows performing sub calls to different Palmyra model types. As well as `Graph` tool `LLM` tool is a remotely executing tool, which means you don't have to worry about its execution: Writer server will do it for you. To learn more, see our [LLM tool docs](https://dev.writer.com/api-guides/model-delegation#tool-object).\n",
    "\n",
    "#### No-code app\n",
    "\n",
    "The `No-code app` tool is a wrapper for Writer [no-code apps](https://dev.writer.com/api-guides/applications#no-code-applications) to use them as tools for LLM. In distinguish from `Graph` and `LLM` tools `No-code app` tool requires manual execution and passing tool call results into messages history, because it's based on usual `function` tool type. For further information see our [No-code apps as tool docs](https://dev.writer.com/api-guides/applications-tool-calling#no-code-applications-as-tools)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40136062a4c267f3",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "\n",
    "\n",
    "### Installation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%pip install -qU langchain-writer",
   "id": "b7e0f6a802c9eb35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Credentials\n",
    "\n",
    "Sign up for [Writer AI Studio](https://app.writer.com/aistudio/signup?utm_campaign=devrel) to generate an API key (you can follow this [Quickstart](https://dev.writer.com/api-guides/quickstart)). Then, set the WRITER_API_KEY environment variable:"
   ],
   "id": "381885fa319b465a"
  },
  {
   "cell_type": "code",
   "id": "80d4e1a791aaa8",
   "metadata": {},
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"WRITER_API_KEY\"):\n",
    "    os.environ[\"WRITER_API_KEY\"] = getpass.getpass(\"Enter your Writer API key: \")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1c97218f-f366-479d-8bf7-fe9f2f6df73f",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "You can bind graph or function tools to `ChatWriter`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e4abffc12774",
   "metadata": {},
   "source": [
    "### Graph Tools\n",
    "\n",
    "To bind graph tools, first create and initialize a `GraphTool` instance with the `graph_ids` you want to use as sources:"
   ]
  },
  {
   "cell_type": "code",
   "id": "6faaae25509f0f28",
   "metadata": {},
   "source": [
    "from langchain_writer.chat_models import ChatWriter\n",
    "from langchain_writer.tools import GraphTool\n",
    "\n",
    "chat = ChatWriter()\n",
    "\n",
    "graph_id = getpass.getpass(\"Enter Writer Knowledge Graph ID: \")\n",
    "graph_tool = GraphTool(graph_ids=[graph_id])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### LLM Tools\n",
    "\n",
    "To bind LLM tools, first create and initialize a `LLMTool` instance with the `model_name` you want to use as sources:"
   ],
   "id": "d3324f13e01c6356"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_writer.tools import LLMTool\n",
    "\n",
    "llm_tool = LLMTool(model_name=\"palmyra-med\")"
   ],
   "id": "1b0d29959b9ee2f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### No-code app Tools\n",
    "\n",
    "To bind no-code app tools, first create and initialize a `NoCodeAppTool` instance with the `app_id` you want to use as sources:"
   ],
   "id": "c49c8fb82ce170c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_writer.tools import NoCodeAppTool\n",
    "\n",
    "app_id = getpass.getpass(\"Enter App ID: \")\n",
    "app_tool = NoCodeAppTool(app_id=app_id)"
   ],
   "id": "547b2bba2bf7952c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50ea16fc3a382cf",
   "metadata": {},
   "source": "## Instantiation"
  },
  {
   "cell_type": "code",
   "id": "e98d7deedb0e5c6f",
   "metadata": {},
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_supercopa_trophies_count(club_name: str) -> Optional[int]:\n",
    "    \"\"\"Returns information about supercopa trophies count.\n",
    "\n",
    "    Args:\n",
    "        club_name: Club you want to investigate info of supercopa trophies about\n",
    "\n",
    "    Returns:\n",
    "        Number of supercopa trophies or None if there is no info about requested club\n",
    "    \"\"\"\n",
    "\n",
    "    if club_name == \"Barcelona\":\n",
    "        return 15\n",
    "    elif club_name == \"Real Madrid\":\n",
    "        return 13\n",
    "    elif club_name == \"Atletico Madrid\":\n",
    "        return 2\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "class GetWeather(BaseModel):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "\n",
    "    location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
    "\n",
    "\n",
    "get_product_info = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_product_info\",\n",
    "        \"description\": \"Get information about a product by its id\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"product_id\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The unique identifier of the product to retrieve information for\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"product_id\"],\n",
    "        },\n",
    "    },\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1753ca46",
   "metadata": {},
   "source": [
    "### Binding tools\n",
    "Then, you can simply bind all tools to the `ChatWriter` instance:"
   ]
  },
  {
   "cell_type": "code",
   "id": "a4833f2597a87777",
   "metadata": {},
   "source": [
    "chat_with_tools = chat.bind_tools(\n",
    "    [graph_tool, llm_tool, app_tool, get_supercopa_trophies_count, GetWeather, get_product_info]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "74147a1a",
   "metadata": {},
   "source": [
    "## Invocation\n",
    "\n",
    "The model will automatically choose the tool during invocation with all modes (streaming/non-streaming, sync/async)."
   ]
  },
  {
   "cell_type": "code",
   "id": "74df06b58b5dc2e9",
   "metadata": {},
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        \"Use knowledge graph tool to compose this answer. Tell me what th first line of documents stored in your KG. Also I want to know: how many SuperCopa trophies have Barcelona won?\"\n",
    "    )\n",
    "]\n",
    "\n",
    "response = chat_with_tools.invoke(messages)\n",
    "messages.append(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b015fdb2",
   "metadata": {},
   "source": [
    "In the case of function tools, you will receive an assistant message with the tool call request."
   ]
  },
  {
   "cell_type": "code",
   "id": "e271e0fc677446b2",
   "metadata": {},
   "source": [
    "print(response.tool_calls)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aeff6a17ce3176b1",
   "metadata": {},
   "source": [
    "Then you can manually handle tool call request, send to model and receive final response:"
   ]
  },
  {
   "cell_type": "code",
   "id": "156b58108aa9b367",
   "metadata": {},
   "source": [
    "for tool_call in response.tool_calls:\n",
    "    selected_tool = {\n",
    "        \"get_supercopa_trophies_count\": get_supercopa_trophies_count,\n",
    "    }[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "response = chat_with_tools.invoke(messages)\n",
    "print(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ff9347b2",
   "metadata": {},
   "source": "With a `GraphTool` and `LLMTool`, the model will call it remotely and return usage info in the `additional_kwargs` under the `graph_data` and `llm_data` keys respectively:"
  },
  {
   "cell_type": "code",
   "id": "4b3c6f05096fc9e3",
   "metadata": {},
   "source": [
    "print(response.additional_kwargs[\"graph_data\"])\n",
    "print(response.additional_kwargs[\"llm_data\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f001d2ca",
   "metadata": {},
   "source": [
    "The `content` attribute contains the final response:"
   ]
  },
  {
   "cell_type": "code",
   "id": "eb6e0da74b10b8fc",
   "metadata": {},
   "source": [
    "print(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "602631cd878e5dbe",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "Due to specificity of Writer Graph and LLM tools (you don't need to call it manually, Writer server will call it by himself and return RAG/sub LLM call based generation) it's impossible to invoke them separately, so `GraphTool` and `LLMTool` can't be used as part of chain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
