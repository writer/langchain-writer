{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Chat Writer\n",
    "\n",
    "This notebook provides a quick overview for getting started with Writer [chat](/docs/concepts/chat_models/).\n",
    "\n",
    "Writer has several chat models. You can find information about their latest models and their costs, context windows, and supported input types in the [Writer docs](https://dev.writer.com/home).\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Integration details\n",
    "| Class                                                                                                                                         | Package          | Local | Serializable | JS support |                                        Package downloads                                         |                                        Package latest                                         |\n",
    "|:----------------------------------------------------------------------------------------------------------------------------------------------|:-----------------| :---: | :---: |:----------:|:------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n",
    "| [ChatWriter](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.langchain_writer.tool.ChatWriter.html) | [langchain-writer](https://api.python.langchain.com/en/latest/community_api_reference.html) |      ❌       |                                       ❌                                       | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-writer?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-writer?style=flat-square&label=%20) |\n",
    "### Model features\n",
    "| [Tool calling](/docs/how_to/tool_calling) | Structured output | JSON mode | Image input | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async |         [Token usage](/docs/how_to/chat_token_usage_tracking/)          | Logprobs |\n",
    "| :---: |:-----------------:| :---: | :---: |  :---: | :---: | :---: | :---: |:--------------------------------:|:--------:|\n",
    "| ✅ |         ❌         | ❌ | ❌ | ❌ | ❌ | ✅ | ✅ |                ✅                 |    ❌     |"
   ],
   "id": "e815de6298bf07ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Credentials\n",
    "\n",
    "Head to [Writer AI Studio](https://app.writer.com/aistudio/signup?utm_campaign=devrel) to sign up and generate an API key. Once you've done this set the WRITER_API_KEY environment variable. It's necessary to create ChatWriter instance:"
   ],
   "id": "72c88ac5caefe913"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"WRITER_API_KEY\"):\n",
    "    os.environ[\"WRITER_API_KEY\"] = getpass.getpass(\"Enter your Writer API key: \")"
   ],
   "id": "d9242a5ee155aaf5"
  },
  {
   "cell_type": "markdown",
   "id": "72ee0c4b-9764-423a-9dbf-95129e185210",
   "metadata": {},
   "source": [
    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
   ]
  },
  {
   "cell_type": "code",
   "id": "a15d341e-3e26-4ca3-830b-5aab30ed66de",
   "metadata": {},
   "source": [
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0730d6a1-c893-4840-9817-5e5251676d5d",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "The LangChain Writer integration lives in the `langchain-writer` package:"
   ]
  },
  {
   "cell_type": "code",
   "id": "652d6238-1f87-422a-b135-f5abbb8652fc",
   "metadata": {},
   "source": [
    "%pip install -qU langchain-writer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a38cde65-254d-4219-a441-068766c0d4b5",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions:"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb09c344-1836-4e0c-acf8-11d13ac1dbae",
   "metadata": {},
   "source": [
    "from langchain_writer import ChatWriter\n",
    "\n",
    "llm = ChatWriter(\n",
    "    model=\"palmyra-x-004\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3e15",
   "metadata": {},
   "source": "## Invocation"
  },
  {
   "cell_type": "code",
   "id": "62e0dbc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d86145b3-bfef-46e8-b227-4dda5c9c2705",
   "metadata": {},
   "source": [
    "print(ai_msg.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Streaming",
   "id": "4391289ce0a80e19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming. Sing a song about it\"),\n",
    "]\n",
    "ai_stream = llm.stream(messages)\n",
    "ai_stream"
   ],
   "id": "4a0f2112b3a4c79e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for chunk in ai_stream:\n",
    "    print(chunk.content, end=\"\")"
   ],
   "id": "8c4b7b9b9308c757",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tool calling\n",
    "\n",
    "Writer supports [tool calling](https://dev.writer.com/api-guides/tool-calling), which lets you describe tools and their arguments, and have the model return a JSON object with a tool to invoke and the inputs to that tool.\n",
    "\n",
    "### ChatWriter.bind_tools()\n",
    "\n",
    "With `ChatWriter.bind_tools`, we can easily pass in Pydantic classes, dict schemas, LangChain tools, or even functions as tools to the model. Under the hood these are converted to tool schemas, which looks like:\n",
    "```\n",
    "{\n",
    "    \"name\": \"...\",\n",
    "    \"description\": \"...\",\n",
    "    \"parameters\": {...}  # JSONSchema\n",
    "}\n",
    "```\n",
    "and passed in every model invocation."
   ],
   "id": "e632bf7d0873f933"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class GetWeather(BaseModel):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "\n",
    "    location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
    "\n",
    "\n",
    "llm.bind_tools([GetWeather])"
   ],
   "id": "47e2f0faceca533",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ai_msg = llm.invoke(\n",
    "    \"what is the weather like in New York City\",\n",
    ")\n",
    "ai_msg"
   ],
   "id": "765527dd533ec967",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(ai_msg.tool_calls)",
   "id": "f361c4769e772fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Important feature\n",
    "\n",
    "ChatWriter ___bind_tools()___ method have specific functionality: it doesn't create new instance with binded tools, but store received tools and tool_choice in initial class instance attributes, to pass them as parameters during Palmyra LLM call while Chat invocation. Pay attention about it while using ChatWriter class with tools calling. This approach allows to support different tool types e.g. __function__ and __graph__. __Graph__ - is one of remotely called Writer Palmyra tools type. For further information visit our [docs](https://dev.writer.com/api-guides/knowledge-graph#knowledge-graph). For more information about tools usage visit tools docs."
   ],
   "id": "3baf53021834d2ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Batching",
   "id": "a4674b1b82ce9d1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ai_batch = llm.batch(\n",
    "    [\n",
    "        \"How to cook pancakes?\",\n",
    "        \"How to compose poem?\",\n",
    "        \"How to run faster?\",\n",
    "    ],\n",
    "    config={\"max_concurrency\": 3},\n",
    ")\n",
    "ai_batch"
   ],
   "id": "c8a217f6190747fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for batch in ai_batch:\n",
    "    print(batch.content)\n",
    "    print(\"-\"*100)"
   ],
   "id": "b6a228d448f3df23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Async\n",
    "\n",
    "All features above (invocation, streaming, batching, tools calling) also support asynchronous usage!"
   ],
   "id": "58a9ab241fe09a71"
  },
  {
   "cell_type": "markdown",
   "id": "18e2bfc0-7e78-4528-a73f-499ac150dca8",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "You can [chain](/docs/how_to/sequence/) our model with a prompt template like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e197d1d7-a070-4c96-9f8a-a0e86d046e0b",
   "metadata": {},
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all ChatWriter features and configurations head to the [API reference](https://python.langchain.com/api_reference/writer/chat_models/langchain_writer.chat_models.ChatWriter.html#langchain_writer.chat_models.ChatWriter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
